
## 步骤
- 文档Trainer过一遍
- trainer结构梳理
- 总结
- run_clm梳理
- 文档中 TrainingArguments每个参数的怎么发挥作用
- 



## Traier入参
- `data_collator` (DataCollator, optional) — The function to use to form a batch from a list of elements of train_dataset or eval_dataset. **Will default to default_data_collator(). if no tokenizer is provided, an instance of DataCollatorWithPadding otherwise.**
- `tokenizer` (PreTrainedTokenizerBase, optional) — The tokenizer used to preprocess the data. If provided, **will be used to automatically pad the inputs to the maximum length when batching inputs**, and it will be saved along the model to make it easier to rerun an interrupted training or reuse the fine-tuned model.
- `model_init`(Callable[[], PreTrainedModel], optional) — A function that instantiates the model to be used. If provided, **each call to train() will start from a new instance of the model as given by this function.**

- `compute_metrics` #TODO
- `optimizers` (Tuple[torch.optim.Optimizer, torch.optim.lr_scheduler.LambdaLR], optional, defaults to (None, None)) — A tuple containing the optimizer and the scheduler to use. Will default to an instance of AdamW on your model and a scheduler given by `get_linear_schedule_with_warmup()` controlled by args.
- preprocess_logits_for_metrics #TODO

### 重要属性
- `place_model_on_device` — Whether or not to automatically place the model on the device - **it will be set to False if model parallel or deepspeed is used**, or if the default TrainingArguments.place_model_on_device is overridden to return False .



DefaultFlowCallback 设定了一些每个step和每个epoch结束时的行为

## Trainer怎么控制log, save, evaluate的
- 在训练的特殊节点都会尝试进行log_save_evaluate，是根据control变量的相关属性来决定是否分别做log_save_evaluate
- 而control变量的相关属性在 DefaultFlowCallback 的相关callback_step被调用时会被修改，例如on_step_end中会设置control.should_log, control.should_evaluate,而这些值的设定也是根据TrainingArgumens中的可配置参数设定的。
- 思考为什么要这么实现：**首先我们会通过TrainingArgumens设定什么时候进行log, save, evaluate；那么我们在Trainer.train的每个特殊节点都需要判断是否要进行log_save_evaluate，既然很多地方要重复写，那这三个操作可以抽象为一个函数_maybe_log_save_evaluate，但是这个函数要包含一个入参——时机，因为不同的时机这个函数的具体操作是不同的，比如step_end要log，epoch_end不要log；所以定义一个control变量来区分不同时机，不同的时机下control变量是怎么根据情况变化的呢？是通过callback_step让control在不同的时机产生不同的行为；callback_step在每个时机是靠什么决定control变化的呢，当然是根据最初的TrainingArguments设定的参数啦！**



## TrainingArguments参数梳理
- `logging_steps` (int or float, optional, defaults to 500) 
    - Number of update steps between two logs if `logging_strategy="steps"`. Should be an integer or a float in range [0,1). If smaller than 1, will be interpreted as ratio of total training steps.

- `logging_strategy` (str or IntervalStrategy, optional, **defaults to "steps"**)
    - The logging strategy to adopt during training. Possible values are:  
        - "no": No logging is done during training.
        - "epoch": Logging is done at the end of each epoch.
        - "steps": Logging is done every logging_steps.


- `eval_steps` (int or float, optional) 
    - Number of update steps between two evaluations if eval_strategy="steps". **Will default to the same value as logging_steps if not set.** Should be an integer or a float in range [0,1). If smaller than 1, will be interpreted as ratio of total training steps.

- `eval_strategy` (str or IntervalStrategy, optional, **defaults to "no"**)
    - The evaluation strategy to adopt during training. Possible values are:
        - "no": No evaluation is done during training.
        - "steps": Evaluation is done (and logged) every eval_steps.
        - "epoch": Evaluation is done at the end of each epoch.

- `save_steps` (int or float, optional, **defaults to 500**)
    - Number of updates steps before two checkpoint saves if save_strategy="steps". Should be an integer or a float in range [0,1). If smaller than 1, will be interpreted as ratio of total training steps.

- `save_strategy` (str or IntervalStrategy, optional, **defaults to "steps"**) 
    - The checkpoint save strategy to adopt during training. Possible values are:
        - "no": No save is done during training.
        - "epoch": Save is done at the end of each epoch.
        - "steps": Save is done every save_steps.
    - If "epoch" or "steps" is chosen, saving will also be performed at the very end of training, always.


- `max_steps` (int, optional, defaults to -1)
    - If set to a positive number, the total number of training steps to perform. Overrides num_train_epochs. For a finite dataset, training is reiterated through the dataset (if all data is exhausted) until max_steps is reached.

- `num_train_epochs` (float, optional, defaults to 3.0) 
    - Total number of training epochs to perform (if not an integer, will perform the decimal part percents of the last epoch before stopping training).

- `train_batch_size` 
    - 分布式训练时，就等于 `per_device_train_batch_size`


- `n_gpu` 
    - 当前进程使用的GPU数量，**分布式训练时，该属性总是固定为1**，只有在未使用分布式才可能大于1。









## 关于判断 model
- 在这段代码中，条件 `use_accelerator_prepare = True if model is self.model else False` 是用来判断是否要使用 `accelerator.prepare` 方法来准备模型。下面我详细解释其原因：

1. **模型封装**：`model = self._wrap_model(self.model_wrapped)` 表示模型已经通过某种方式被封装（wrapped）。封装模型的原因可能是为了兼容不同的加速框架（如分布式训练、XLA、SageMaker 等）。这种封装可能会改变模型的外层结构，使其与原来的模型对象 `self.model` 不同。

2. **加速器准备（accelerator.prepare）**：
   - `accelerator.prepare` 是一个常见的方法，用于准备模型以适配分布式训练或者其他硬件加速器（比如 GPU、TPU）。
   - 但是，当模型被封装之后（特别是在处理复杂的分布式场景，如 FSDP-XLA、SageMaker MP/DP、DataParallel、IPEX 等），模型结构已经被修改，直接对封装后的模型调用 `accelerator.prepare` 可能会不合适或多余。
   - 因此，代码里引入了这个条件：如果 `model` 仍然是未封装的原始模型 `self.model`，那么就使用 `accelerator.prepare`，否则不使用。

3. **判断逻辑**：
   - `model is self.model`：这个条件判断当前的 `model` 对象是否与原始的 `self.model` 是同一个对象（即没有被封装过）。如果 `model` 和 `self.model` 是同一个对象，说明模型没有经过封装，此时可以安全地使用 `accelerator.prepare`。
   - 如果 `model` 不是 `self.model`，说明模型已经被封装成了一个新的对象（如为分布式训练或加速优化做准备），此时不应该再使用 `accelerator.prepare`，因为模型已经被处理过了。

### 总结：
- 如果 `model` 和 `self.model` 是同一个对象（即没有被封装），则 `use_accelerator_prepare` 为 `True`，表明可以调用 `accelerator.prepare` 来准备模型。
- 如果 `model` 经过封装（例如为了适配特殊加速器或分布式训练场景），则 `use_accelerator_prepare` 为 `False`，以避免重复处理模型。

这段代码的逻辑确保了在复杂的分布式训练或硬件加速场景下，不对已经处理过的封装模型进行不必要的加速器准备。


- **那为啥不写成 model = self._wrap_model(self.model) ？**
这是一个非常好的问题！在你的代码片段中，模型是通过 `model = self._wrap_model(self.model_wrapped)` 进行封装的，而你提出的疑问是，为什么不直接使用 `model = self._wrap_model(self.model)`。

这个设计的原因可以归结为以下几点：

### 1. **`self.model_wrapped` 可能已经是封装后的模型**：
   - `self.model_wrapped` 很可能已经是封装后的模型对象，而不是原始的 `self.model`。例如，`self.model_wrapped` 可能已经过某种加速或分布式处理，或者经过某种预处理、包装或转换操作。
   - 通过使用 `self.model_wrapped`，代码可以避免重复封装。如果直接封装 `self.model`，则可能会对模型进行重复的包装或处理，导致潜在的性能开销或不必要的复杂性。

### 2. **封装后模型的兼容性**：
   - 在某些场景下（例如分布式训练、硬件加速等），模型可能需要通过多层封装来兼容不同的加速器或分布式策略。`self.model_wrapped` 可能代表已经完成了部分封装的模型，而 `self.model` 是原始未封装的模型。
   - 如果你直接对 `self.model` 进行封装，可能会丢失之前封装步骤中的某些重要处理。`self._wrap_model(self.model_wrapped)` 能确保当前的模型保持已有的封装状态，同时再进行进一步封装。

### 3. **设计灵活性**：
   - 通过使用 `self.model_wrapped`，代码可以更灵活地处理不同的模型状态。`self.model_wrapped` 和 `self.model` 可以是不同的对象，前者可以经过一些复杂的封装，后者保持原始状态。这样一来，代码可以根据场景选择是基于原始模型还是已经封装过的模型继续封装，增强代码的可扩展性和灵活性。
   - 如果直接用 `self.model`，就会固定为每次都基于原始模型封装，缺乏了处理已经封装模型的能力，导致模型封装过程变得冗余或难以处理复杂的分布式场景。

### 4. **避免不必要的包装**：
   - 如果已经有一些封装过程在之前发生（比如 `self.model_wrapped` 已经封装好了某些功能），那么再重复封装 `self.model` 会导致额外的性能开销或不必要的复杂性。特别是对于大规模分布式模型，重复封装可能带来问题。

### 5. **封装策略的区分**：
   - 代码中的 `self.model` 和 `self.model_wrapped` 可能对应不同的封装策略或过程。`self.model` 表示原始模型，`self.model_wrapped` 表示经过部分封装处理的模型，而 `_wrap_model()` 可能是进一步的包装方法。
   - 通过这种方式，代码可以在不同封装状态下（原始、部分封装、完全封装）保持灵活性，而不是一刀切地总是从原始模型开始封装。

### 总结：
- 使用 `self.model_wrapped` 而不是 `self.model`，是为了确保封装步骤是基于当前封装状态（即 `self.model_wrapped`），而不是重复从原始模型封装。
- 这提供了更好的灵活性、性能优化和兼容性处理，特别是在复杂的训练和加速场景下。

简单来说，`self.model_wrapped` 可能代表已经封装过的模型，而 `self.model` 代表原始模型。通过对 `self.model_wrapped` 进行进一步封装，可以避免重复封装，并确保模型保持正确的封装状态。